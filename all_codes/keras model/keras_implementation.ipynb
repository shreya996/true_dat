{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "# SKLEARN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 16567\n",
      "vsplit: 11596\n",
      "tsplit: 4971\n",
      "2485\n",
      "CLASS LABELS: ['CEP', 'LPV']\n",
      "TRAINING IMAGES: 11596\n",
      "VALIDATION IMAGES: 2485\n",
      "TEST IMAGES: 2486\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import glob\n",
    "import sys\n",
    "################### DATASET HANDLING ####################\n",
    "DATASET_PATH = \"/home/dic/jupyter/train_Binary\" #change the path to your dataset folder here\n",
    "\n",
    "def parseDataset():\n",
    " \n",
    "    #we use subfolders as class labels\n",
    "    classes = [folder for folder in sorted(os.listdir(DATASET_PATH))]\n",
    " \n",
    "    #now we enlist all image paths\n",
    "    images = []\n",
    "    for c in classes:\n",
    "        images += ([os.path.join(DATASET_PATH, c, path) for path in os.listdir(os.path.join(DATASET_PATH, c))])\n",
    "    #print(images)\n",
    "    #shuffle image paths\n",
    "    images = shuffle(images, random_state=74)\n",
    " \n",
    "    #we want to use a 15% validation split\n",
    "    total_len=len(images)\n",
    "    print(\"total:\",total_len)\n",
    "    vsplit = int(len(images) * 0.70) #=40\n",
    "    print(\"vsplit:\",vsplit)\n",
    "    \n",
    "    tsplit= int(total_len-vsplit)\n",
    "    print(\"tsplit:\",tsplit)\n",
    "    \n",
    "    gsplit=int(tsplit/2)\n",
    "    print(gsplit)\n",
    "    msplit=int(vsplit+gsplit)\n",
    "    \n",
    "    \n",
    "    train = images[:vsplit] #everything except the last vsplit items in the array \n",
    "    val = images[vsplit:msplit]  #only last vsplit items from the array\n",
    "    test=images[msplit:]\n",
    "    #show some stats\n",
    "    print (\"CLASS LABELS:\", classes)\n",
    "    print (\"TRAINING IMAGES:\", len(train))\n",
    "    print (\"VALIDATION IMAGES:\", len(val))\n",
    "    print (\"TEST IMAGES:\", len(test))\n",
    "    return classes, train, val,test\n",
    " \n",
    "#parse dataset\n",
    "CLASSES, TRAIN, VAL,TEST = parseDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-c02cfe86c085>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;31m#print(y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img_p=[] \n",
    "#################### BATCH HANDLING #####################\n",
    "def loadImageAndTarget(path):\n",
    "    #print(path)\n",
    "    #here we open the image and scale it to 64x64 pixels\n",
    "    img = cv2.imread(path)\n",
    "    \n",
    "    #print(path)\n",
    "    img = cv2.resize(img, (22, 23))\n",
    "    \n",
    "    \n",
    "    #OpenCV uses BGR instead of RGB, but for now we can ignore that\n",
    "    #our image has the shape (64, 64, 3) but we need it to be (3, 64, 64)\n",
    "    img = np.transpose(img, (2, 1, 0))\n",
    "    \n",
    "    #we want to use subfolders as class labels\n",
    "    label = path.split(os.sep[-1])[-2]\n",
    "    #print(label)\n",
    " \n",
    "    #we need to get the index of our label from CLASSES\n",
    "    index = CLASSES.index(label)\n",
    " \n",
    "    #allocate array for target\n",
    "    target = np.zeros((2), dtype='float32')\n",
    " \n",
    "    #we set our target array = 1.0 at our label index, all other entries remain zero\n",
    "    #Example: if label = dog and dog has index 2 in CLASSES, target looks like: [0.0, 0.0, 1.0, 0.0, 0.0]\n",
    "    target[index] = 1.0\n",
    " \n",
    "    #we need a 4D-vector for our image and a 2D-vector for our targets\n",
    "    #we can adjust array dimension with reshape\n",
    "    img = img.reshape(-1, 3, 22, 23)\n",
    "    target = target.reshape(-1, 2)\n",
    "    img_p.append(img)\n",
    "    return img, target\n",
    "print(img_p)\n",
    "\n",
    "#a reasonable size for one batch is 128\n",
    "BATCH_SIZE = 200\n",
    "def getDatasetChunk(split):\n",
    " \n",
    "    #get batch-sized chunks of image paths\n",
    "    for i in range(0, len(split), BATCH_SIZE):\n",
    "        yield split[i:i+BATCH_SIZE]\n",
    "        \n",
    "def getNextImageBatch(split):    \n",
    " \n",
    "    #allocate numpy arrays for image data and targets\n",
    "    #input shape of our ConvNet is (None, 3, 22, 23)\n",
    "    x_b = np.zeros((BATCH_SIZE, 3, 22, 23), dtype='float32')\n",
    "    #output shape of our ConvNet is (None, 5) as we have 5 classes\n",
    "    y_b = np.zeros((BATCH_SIZE, 2), dtype='float32')\n",
    " \n",
    "    #fill batch\n",
    "    for chunk in getDatasetChunk(split):        \n",
    "        ib = 0\n",
    "        for path in chunk:\n",
    "            #load image data and class label from path\n",
    "            x, y = loadImageAndTarget(path)\n",
    " \n",
    "            #pack into batch array\n",
    "            x_b[ib] = x\n",
    "            y_b[ib] = y\n",
    "            ib += 1\n",
    " \n",
    "        #instead of return, we use yield\n",
    "        yield x_b[:len(chunk)], y_b[:len(chunk)]\n",
    "#x_train= np.array()\n",
    "x_train=[]\n",
    "y_train=[]\n",
    "for image_batch, target_batch in getNextImageBatch(TRAIN):\n",
    "    x_train.append(image_batch)\n",
    "#    x_train.append(image_batch)\n",
    "    y_train.append(target_batch)\n",
    "x_train = np.array(x_train)  \n",
    "\n",
    "#print(y_train)        \n",
    "\n",
    "\n",
    "\n",
    "x_test=[]\n",
    "y_test=[]\n",
    "for image_batch, target_batch in getNextImageBatch(TEST):\n",
    "        x_test.append(image_batch)\n",
    "        y_test.append(target_batch)\n",
    "\n",
    "\n",
    "x_val=[]\n",
    "y_val=[]\n",
    "for image_batch, target_batch in getNextImageBatch(VAL):\n",
    "        \n",
    "        x_val.append(image_batch)\n",
    "        y_val.append(target_batch)  \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "1   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "2   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "3   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "4   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "5   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "6   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "7   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "8   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "9   [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "10  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "11  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "12  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "13  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "14  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "15  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "16  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "17  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "18  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "19  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "20  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "21  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "22  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "23  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "24  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "25  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "26  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "27  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "28  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "29  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "30  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "31  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "32  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "33  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "34  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "35  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "36  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "37  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "38  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "39  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "40  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "41  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "42  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "43  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "44  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "45  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "46  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "47  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "48  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "49  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "50  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "51  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "52  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "53  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "54  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "55  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "56  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n",
      "57  [[[[128. 128. 128. 128. 128. 128. 128. 128. 12...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_x=pd.DataFrame(x_train) \n",
    "print(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x= data.iloc[:,1:].values.reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lasagne import layers\n",
    "from lasagne.nonlinearities import softmax, tanh\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "img_rows=22\n",
    "img_cols=23\n",
    "num_classes=2\n",
    "input_shape = (3, img_rows, img_cols) \n",
    "################## BUILDING THE MODEL ###################\n",
    "#def buildModel():\n",
    "\n",
    "    #this is our input layer with the inputs (None, dimensions, width, height)\n",
    "    #l_input = layers.InputLayer((None, 3, 22, 23))\n",
    "model = Sequential()    \n",
    "    #first convolutional layer, has l_input layer as incoming and is followed by a pooling layer\n",
    "    #l_conv1 = layers.Conv2DLayer(l_input, num_filters=32, filter_size=3, nonlinearity=lasagne.nonlinearities.tanh)\n",
    "model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    \n",
    "    #l_pool = layers.MaxPool2DLayer(l_conv1, pool_size=2)\n",
    "    \n",
    "    #l_drop1= layers.DropoutLayer(l_conv1,  p=0.1)\n",
    "model.add(Dropout(0.1))\n",
    "    #l_dense1 = layers.DenseLayer(l_drop1, num_units=128)\n",
    "    \n",
    "    #l_conv2 = layers.Conv2DLayer(l_drop1, num_filters=128, filter_size=5, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "    \n",
    "   \n",
    "    #l_conv3 = layers.Conv2DLayer(l_conv2, num_filters=256, filter_size=5, nonlinearity=lasagne.nonlinearities.rectify)\n",
    "model.add(Flatten())\n",
    "    #l_dense2 = layers.DenseLayer(l_drop1, num_units=128)\n",
    "model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    #l_drop2= layers.DropoutLayer(l_dense2,  p=0.25)\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "    #l_dense2 = layers.DenseLayer(l_drop2, num_units=128)\n",
    "model.add(Dense(128, activation='relu'))\n",
    "    \n",
    "    #l_output = layers.DenseLayer(l_dense2, num_units=7, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "model.add(Dense(num_classes,activation='softmax', name='preds'))\n",
    "    #let's see how many params our net has\n",
    "    #print (\"MODEL HAS\", layers.count_params(l_output), \"PARAMS\")\n",
    "    \n",
    "    #we return the layer stack as our network by returning the last layer\n",
    "    #return model\n",
    "#print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############COMPILING#############\n",
    "batch_size = 256\n",
    "epochs = 10\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dic/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 58 arrays: [array([[[[128., 128., 128., ..., 128., 128., 128.],\n         [128., 128., 128., ..., 128., 128., 128.],\n         [128., 128., 128., ..., 128., 128., 128.],\n         ...,\n         [128.,   0.,   0., ....",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-7cde5e5ed57e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(x_train, y_train, \n\u001b[0;32m----> 2\u001b[0;31m           batch_size=32, nb_epoch=10, verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 58 arrays: [array([[[[128., 128., 128., ..., 128., 128., 128.],\n         [128., 128., 128., ..., 128., 128., 128.],\n         [128., 128., 128., ..., 128., 128., 128.],\n         ...,\n         [128.,   0.,   0., ...."
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, y_train, \n",
    "          batch_size=32, nb_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 58 into shape (58,1,22,23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-2fef56785666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 58 into shape (58,1,22,23)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train = np.asarray(x_train)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],1, img_rows, img_cols)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 3)\n",
    "x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 3)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_val = x_val.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "x_val /= 255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 58 arrays: [array([[[[128., 128., 128., ..., 128., 128., 128.],\n         [128., 128., 128., ..., 128., 128., 128.],\n         [128., 128., 128., ..., 128., 128., 128.],\n         ...,\n         [128.,   0.,   0., ....",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-259ecd201a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           validation_data=(x_val, y_val))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    951\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 58 arrays: [array([[[[128., 128., 128., ..., 128., 128., 128.],\n         [128., 128., 128., ..., 128., 128., 128.],\n         [128., 128., 128., ..., 128., 128., 128.],\n         ...,\n         [128.,   0.,   0., ...."
     ]
    }
   ],
   "source": [
    "###########Training###################\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
